{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"Keras Fashion MNIST","provenance":[{"file_id":"1iccoUX-HumXNxcCRXW-7msh3vZdwJ6_0","timestamp":1589775553516},{"file_id":"1zTu32Rx-YenEK5sWnyojETkgCeJVxiB-","timestamp":1589393354501},{"file_id":"https://github.com/tensorflow/tpu/blob/master/tools/colab/fashion_mnist.ipynb","timestamp":1589390678774}],"collapsed_sections":["N6ZDpd9XzFeN"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"N6ZDpd9XzFeN"},"source":["##### Copyright 2018 The TensorFlow Hub Authors.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");"]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"KUu4vOt5zI9d","colab":{}},"source":["# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# =============================================================================="],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"edfbxDDh2AEs"},"source":["## Fashion MNIST with Keras and TPUs"]},{"cell_type":"code","metadata":{"id":"4kboSIlkkIQZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RNo1Vfghpa8j"},"source":["## Overview\n","\n","In this example, you can try out using tf.keras and Cloud TPUs to train a model on the fashion MNIST dataset. The model trains for 10 epochs on Cloud TPU and takes approximately 2 minutes to run.\n","\n","This notebook is hosted on GitHub. To view it in its original repository, after opening the notebook, select **File > View on GitHub**."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dgAHfQtuhddd"},"source":["## Learning objectives\n","\n","In this Colab, you will learn how to:\n","*   Code for a standard conv-net that has 3 layers with drop-out and batch normalization between each layer in Keras.\n","*   Create and compile the model under a distribution strategy in order ot use TPUs.\n","*   Run a prediction to see how well the model can predict fashion categories and output the result."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QrprJD-R-410"},"source":["## Instructions"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_I0RdnOSkNmi"},"source":["<h3>  &nbsp;&nbsp;Train on TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n","\n","1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n","1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5eEM-XOvURoU"},"source":["TPUs are located in Google Cloud, for optimal performance, they read data directly from Google Cloud Storage (GCS)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zo-Yk6LFGfSf","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Lvo0t7XVIkWZ"},"source":["## Data, model, and training"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MICrRv8rmXVq"},"source":["Begin by downloading the fashion MNIST dataset using `tf.keras.datasets`, as shown below. The fashion dataset from the Modified National Institute of Standards and Technology is a common dataset to learn computer vision from. It consists of 70000 samples where we have a picture of a clothing item and an assigned category for that clothing item."]},{"cell_type":"code","metadata":{"id":"gFWrQovrEu7M","colab_type":"code","outputId":"2c8de385-808e-495c-ce46-21be41f41af4","executionInfo":{"status":"ok","timestamp":1589775595502,"user_tz":420,"elapsed":3419,"user":{"displayName":"Sheershak Agarwal","photoUrl":"","userId":"17586620164807267336"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# import the data\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","\n","# add empty color dimension\n","x_train = np.expand_dims(x_train, -1)\n","x_test = np.expand_dims(x_test, -1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ei3V8akaHauD","colab_type":"text"},"source":["We have 60000 sample in our training data and 10000 samples in our testing data."]},{"cell_type":"code","metadata":{"id":"AdZM1K52G5er","colab_type":"code","outputId":"f07c5534-2f57-4e15-d2ad-2ed11cbabcee","executionInfo":{"status":"ok","timestamp":1589775595503,"user_tz":420,"elapsed":3402,"user":{"displayName":"Sheershak Agarwal","photoUrl":"","userId":"17586620164807267336"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(x_train.shape)\n","print(x_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(60000, 28, 28, 1)\n","(10000, 28, 28, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-1PJdOEdKy1p","colab_type":"text"},"source":["Our feature has dimension (28, 28, 1). It is a 28 x 28 pixelated square with a specified color. Pay attention to the shape of inputs! Passing inputs of the wrong dimension is a common source of code bugs."]},{"cell_type":"code","metadata":{"id":"8UJQZ3d4Kmvq","colab_type":"code","outputId":"c4c7c88e-f5a3-4201-a67a-050885c0683f","executionInfo":{"status":"ok","timestamp":1589775595504,"user_tz":420,"elapsed":3387,"user":{"displayName":"Sheershak Agarwal","photoUrl":"","userId":"17586620164807267336"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(x_train.shape[1:])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(28, 28, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Rhcw9l5EKWAL","colab_type":"text"},"source":["We are trying to predict types of clothing. Each category is given an index."]},{"cell_type":"code","metadata":{"id":"Y7Wme9fWHTEM","colab_type":"code","outputId":"af3a2f42-366a-4284-8f85-bd70d5df79d7","executionInfo":{"status":"ok","timestamp":1589775595505,"user_tz":420,"elapsed":3373,"user":{"displayName":"Sheershak Agarwal","photoUrl":"","userId":"17586620164807267336"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(y_train.shape)\n","print(y_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(60000,)\n","(10000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lhoab378H70c","colab_type":"code","outputId":"436830c8-3af5-4f5f-903b-1f59ead513a7","executionInfo":{"status":"ok","timestamp":1589775595507,"user_tz":420,"elapsed":3361,"user":{"displayName":"Sheershak Agarwal","photoUrl":"","userId":"17586620164807267336"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y_train"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Hgc2FZKVMx15"},"source":["### Define the model\n","\n","The following example uses a standard conv-net that has 3 layers with drop-out and batch normalization between each layer."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"W7gMbs70GxA7","colab":{}},"source":["def create_model():\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n","  model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n","  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","  model.add(tf.keras.layers.Dropout(0.25))\n","\n","  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n","  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n","  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","  model.add(tf.keras.layers.Dropout(0.25))\n","\n","  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n","  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n","  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","  model.add(tf.keras.layers.Dropout(0.25))\n","\n","  model.add(tf.keras.layers.Flatten())\n","  model.add(tf.keras.layers.Dense(256))\n","  model.add(tf.keras.layers.Activation('elu'))\n","  model.add(tf.keras.layers.Dropout(0.5))\n","  model.add(tf.keras.layers.Dense(10))\n","  model.add(tf.keras.layers.Activation('softmax'))\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G_vHRqfeIzRL","colab_type":"text"},"source":["### Train on CPU"]},{"cell_type":"markdown","metadata":{"id":"kcIwLiEpI3Ps","colab_type":"text"},"source":["This is a poor idea. Execute the code, but stop it shortly thereafter by clicking the stop button. We do not have time to waste. BEWARE: we may have to rerun the chunks above this after we halt the execution."]},{"cell_type":"code","metadata":{"id":"CXVXjWugI_Vd","colab_type":"code","outputId":"9a69e716-523d-4fc2-eff7-ea920f9c4766","executionInfo":{"status":"error","timestamp":1589777283029,"user_tz":420,"elapsed":1690864,"user":{"displayName":"Sheershak Agarwal","photoUrl":"","userId":"17586620164807267336"}},"colab":{"base_uri":"https://localhost:8080/","height":460}},"source":["slow_model = create_model()\n","slow_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['sparse_categorical_accuracy'])\n","\n","slow_model.fit(\n","    x_train.astype(np.float32), y_train.astype(np.float32),\n","    epochs=17,\n","    steps_per_epoch=60,\n","    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n","    validation_freq=17\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/17\n","60/60 [==============================] - 737s 12s/step - loss: 1.1204 - sparse_categorical_accuracy: 0.6840\n","Epoch 2/17\n","60/60 [==============================] - 736s 12s/step - loss: 0.5165 - sparse_categorical_accuracy: 0.8203\n","Epoch 3/17\n","14/60 [======>.......................] - ETA: 8:51 - loss: 0.4387 - sparse_categorical_accuracy: 0.8491"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-cdebc14f11ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"qZWHf0rYIgz-","colab_type":"text"},"source":["### Set up TPU Strategy\n"]},{"cell_type":"markdown","metadata":{"id":"T2Lm3OCfIDDO","colab_type":"text"},"source":["We have a lot of data! Training our model will take awhile using only local computer processing units. We will use some free tensor processing units on the cloud to speed up the runtime. Tensor processing units and computer processing units are pieces of computer hardware."]},{"cell_type":"code","metadata":{"id":"JQQLTuCoH_1N","colab_type":"code","colab":{}},"source":["resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","# This is the TPU initialization code that has to be at the beginning.\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","strategy = tf.distribute.experimental.TPUStrategy(resolver)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xLeZATVaNAnE"},"source":["### Train on the TPU\n","\n","To begin training, construct the model on the TPU and then compile it."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pWEYmd_hIWg8","colab":{}},"source":["with strategy.scope():\n","  model = create_model()\n","  model.compile(\n","      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n","      loss='sparse_categorical_crossentropy',\n","      metrics=['sparse_categorical_accuracy'])\n","\n","model.fit(\n","    x_train.astype(np.float32), y_train.astype(np.float32),\n","    epochs=17,\n","    steps_per_epoch=60,\n","    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n","    validation_freq=17\n",")\n","\n","# save the model we built on the cloud\n","# a model is really just its weights\n","model.save_weights('./fashion_mnist.h5', overwrite=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ESL6ltQTMm05"},"source":["### Check the results (inference)\n","\n","Now that you are done training, see how well the model can predict fashion categories!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SaYPv_aKId2d","colab":{}},"source":["# align with the numbered indices of the response variable\n","LABEL_NAMES = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']\n","\n","# make the model on your local computer\n","cpu_model = create_model()\n","\n","# load in the weights we saved from the TPU model\n","cpu_model.load_weights('./fashion_mnist.h5')\n","\n","from matplotlib import pyplot\n","%matplotlib inline\n","\n","# visualize the first 16 predictions\n","def plot_predictions(images, predictions):\n","  n = images.shape[0]\n","  nc = int(np.ceil(n / 4))\n","  f, axes = pyplot.subplots(nc, 4)\n","  for i in range(nc * 4):\n","    y = i // 4\n","    x = i % 4\n","    axes[x, y].axis('off')\n","    \n","    label = LABEL_NAMES[np.argmax(predictions[i])]\n","    confidence = np.max(predictions[i])\n","    if i > n:\n","      continue\n","    axes[x, y].imshow(images[i])\n","    axes[x, y].text(0.5, 0.5, label + '\\n%.3f' % confidence, fontsize=14)\n","\n","  pyplot.gcf().set_size_inches(8, 8)  \n","\n","plot_predictions(np.squeeze(x_test[:16]), \n","                 cpu_model.predict(x_test[:16]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PXB5tTXJnHg0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}